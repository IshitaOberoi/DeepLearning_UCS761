{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "bGWm7DWGOoTQ"
      },
      "outputs": [],
      "source": [
        "AND = [\n",
        "    (0,0,0),\n",
        "    (0,1,0),\n",
        "    (1,0,0),\n",
        "    (1,1,1)\n",
        "]\n",
        "\n",
        "OR = [\n",
        "    (0,0,0),\n",
        "    (0,1,1),\n",
        "    (1,0,1),\n",
        "    (1,1,1)\n",
        "]\n",
        "\n",
        "NAND = [\n",
        "    (0,0,1),\n",
        "    (0,1,1),\n",
        "    (1,0,1),\n",
        "    (1,1,0)\n",
        "]\n",
        "\n",
        "NOR = [\n",
        "    (0,0,1),\n",
        "    (0,1,0),\n",
        "    (1,0,0),\n",
        "    (1,1,0)\n",
        "]\n",
        "\n",
        "XOR = [\n",
        "    (0,0,0),\n",
        "    (0,1,1),\n",
        "    (1,0,1),\n",
        "    (1,1,0)\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_perceptron(dataset, lr, epochs):\n",
        "\n",
        "    w1 = 0\n",
        "    w2 = 0\n",
        "    b = 0\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        for x1, x2, y in dataset:\n",
        "\n",
        "            z = w1*x1 + w2*x2 + b\n",
        "\n",
        "            if z >= 0:\n",
        "                y_hat = 1\n",
        "            else:\n",
        "                y_hat = 0\n",
        "\n",
        "            error = y - y_hat\n",
        "\n",
        "            w1 = w1 + lr * error * x1\n",
        "            w2 = w2 + lr * error * x2\n",
        "            b  = b  + lr * error\n",
        "\n",
        "    return w1, w2, b\n"
      ],
      "metadata": {
        "id": "-pM7g7U6PUki"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_gate(dataset, w1, w2, b):\n",
        "\n",
        "    for x1, x2, y in dataset:\n",
        "\n",
        "        z = w1*x1 + w2*x2 + b\n",
        "\n",
        "        if z >= 0:\n",
        "            pred = 1\n",
        "        else:\n",
        "            pred = 0\n",
        "\n",
        "        print(x1, x2, \"->\", pred, \"| expected:\", y)\n"
      ],
      "metadata": {
        "id": "Acov6fn-PUn6"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gates = {\n",
        "    \"AND\": AND,\n",
        "    \"OR\": OR,\n",
        "    \"NAND\": NAND,\n",
        "    \"NOR\": NOR,\n",
        "    \"XOR\": XOR\n",
        "}\n",
        "\n",
        "lr = 0.1\n",
        "epochs = 20\n",
        "\n",
        "for name in gates:\n",
        "\n",
        "    print(\"\\nTraining\", name)\n",
        "\n",
        "    data = gates[name]\n",
        "\n",
        "    w1, w2, b = train_perceptron(data, lr, epochs)\n",
        "\n",
        "    print(\"Final weights:\", w1, w2)\n",
        "    print(\"Final bias:\", b)\n",
        "\n",
        "    test_gate(data, w1, w2, b)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IRs8HDjvPn_4",
        "outputId": "1236677c-a971-4553-8023-12c62514ecae"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training AND\n",
            "Final weights: 0.2 0.1\n",
            "Final bias: -0.20000000000000004\n",
            "0 0 -> 0 | expected: 0\n",
            "0 1 -> 0 | expected: 0\n",
            "1 0 -> 0 | expected: 0\n",
            "1 1 -> 1 | expected: 1\n",
            "\n",
            "Training OR\n",
            "Final weights: 0.1 0.1\n",
            "Final bias: -0.1\n",
            "0 0 -> 0 | expected: 0\n",
            "0 1 -> 1 | expected: 1\n",
            "1 0 -> 1 | expected: 1\n",
            "1 1 -> 1 | expected: 1\n",
            "\n",
            "Training NAND\n",
            "Final weights: -0.2 -0.1\n",
            "Final bias: 0.2\n",
            "0 0 -> 1 | expected: 1\n",
            "0 1 -> 1 | expected: 1\n",
            "1 0 -> 1 | expected: 1\n",
            "1 1 -> 0 | expected: 0\n",
            "\n",
            "Training NOR\n",
            "Final weights: -0.1 -0.1\n",
            "Final bias: 0.0\n",
            "0 0 -> 1 | expected: 1\n",
            "0 1 -> 0 | expected: 0\n",
            "1 0 -> 0 | expected: 0\n",
            "1 1 -> 0 | expected: 0\n",
            "\n",
            "Training XOR\n",
            "Final weights: -0.1 0.0\n",
            "Final bias: 0.0\n",
            "0 0 -> 1 | expected: 0\n",
            "0 1 -> 1 | expected: 1\n",
            "1 0 -> 0 | expected: 1\n",
            "1 1 -> 0 | expected: 0\n"
          ]
        }
      ]
    }
  ]
}